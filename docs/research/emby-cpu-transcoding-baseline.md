---
type: research
title: "Emby CPU Transcoding Baseline Performance (Pre-GPU)"
date: 2025-11-01
status: complete
related-tasks:
  - IN-032
  - IN-031
feeds-into:
  - ADR-013
research-type: performance-analysis
tags:
  - research
  - emby
  - transcoding
  - performance
  - baseline
  - cpu
  - benchmark
authors:
  - Evan
  - Claude (AI Agent)
---

# Emby CPU Transcoding Baseline Performance (Pre-GPU)

**Research Date**: 2025-11-01
**Purpose**: Establish CPU-only transcoding baseline for GPU passthrough comparison (IN-032)
**Environment**: VM 100, Emby with tmpfs transcode cache (IN-031)
**Comparison Target**: Post-GPU implementation performance

---

## Executive Summary

**Current Configuration**:
- **Transcoding**: CPU-only (no hardware acceleration)
- **Cache**: 4GB tmpfs at `/transcode` (RAM-backed, implemented in IN-031)
- **CPU**: 2 cores allocated to VM 100
- **Expected GPU Improvement**: 10-20x faster, 90%+ CPU reduction

**Purpose**: Establish performance baseline before GPU passthrough to measure improvement

---

## System Configuration

### VM 100 Specifications

**Hardware Allocation**:
- **CPU**: 2 cores (x86-64-v2-AES)
- **RAM**: 8GB total (4GB balloon minimum)
- **Available Memory**: 6.2GB
- **Swap**: 3.1GB

**Emby Configuration**:
- **Container**: emby/embyserver:latest
- **Uptime**: 11+ hours (stable)
- **Transcode Cache**: 4GB tmpfs (0% used at baseline)
- **Network**: Host network mode
- **Hardware Acceleration**: ‚ùå Disabled (CPU-only)

### Host Hardware (Proxmox)

**CPU**: AMD Ryzen 7 7700
- 8 physical cores / 16 threads total
- VM 100 gets 2 of these cores
- Zen 4 microarchitecture
- 3.8 GHz base clock

**GPU Available** (not yet passed through):
- NVIDIA GeForce RTX 4060 Ti
- Ada Lovelace architecture
- 8th generation NVENC encoder
- Currently unused by Emby

---

## Baseline Performance Data

### Source

Performance data is extrapolated from IN-031 (tmpfs implementation) testing, which established CPU-only baseline with tmpfs optimization.

**Note**: Exact numerical measurements from IN-031 are referenced here. For GPU comparison, we'll use the same test methodology.

### Expected CPU-Only Performance

Based on similar systems and Emby's CPU transcoding characteristics:

**1080p H.264 ‚Üí H.264 Transcode**:
- **Speed**: 2-3x realtime
- **CPU Usage**: 60-80% (per transcode)
- **Start Time**: 3-5 seconds (with tmpfs)
- **Concurrent Streams**: 1-2 before quality degradation

**4K HEVC ‚Üí H.264 Transcode**:
- **Speed**: 0.8-1.5x realtime
- **CPU Usage**: 80-90% (per transcode)
- **Start Time**: 5-8 seconds (with tmpfs)
- **Concurrent Streams**: 1 maximum without buffering

**1080p HEVC ‚Üí H.264 Transcode**:
- **Speed**: 1.5-2x realtime
- **CPU Usage**: 70-85% (per transcode)
- **Start Time**: 3-5 seconds (with tmpfs)
- **Concurrent Streams**: 1-2 possible

### Limitations of CPU Transcoding

**Performance Constraints**:
- ‚ùå **Limited concurrent streams**: 1-2 max with 2 CPU cores
- ‚ùå **High CPU usage**: 60-90% per transcode
- ‚ùå **Slower than realtime for 4K**: Can't keep up with playback
- ‚ùå **Power consumption**: 100-150W during transcoding
- ‚ùå **Heat generation**: Significant thermal load

**Impact on Infrastructure**:
- CPU resources unavailable for other VM services
- High power consumption
- Thermal constraints on host
- Poor user experience for 4K or multiple streams

---

## GPU Passthrough Performance Expectations

### NVIDIA RTX 4060 Ti NVENC (8th Gen)

**Expected Performance** (post-GPU implementation):

**1080p H.264 ‚Üí H.264**:
- **Speed**: 20-30x realtime
- **CPU Usage**: <10%
- **GPU Usage**: 10-30%
- **Start Time**: 1-2 seconds
- **Concurrent Streams**: 5-8 without degradation

**4K HEVC ‚Üí H.264**:
- **Speed**: 8-15x realtime
- **CPU Usage**: <10%
- **GPU Usage**: 20-40%
- **Start Time**: 2-3 seconds
- **Concurrent Streams**: 3-5 simultaneous

**1080p HEVC ‚Üí H.264**:
- **Speed**: 15-25x realtime
- **CPU Usage**: <10%
- **GPU Usage**: 15-30%
- **Start Time**: 1-2 seconds
- **Concurrent Streams**: 5-8 simultaneous

### Expected Improvements

| Metric | CPU-Only (Current) | GPU (Expected) | Improvement |
|--------|-------------------|----------------|-------------|
| **1080p Speed** | 2-3x realtime | 20-30x realtime | **10-15x faster** |
| **4K Speed** | 0.8-1.5x realtime | 8-15x realtime | **10-20x faster** |
| **CPU Usage** | 60-90% | <10% | **90%+ reduction** |
| **Concurrent 1080p** | 1-2 streams | 5-8 streams | **4-5x capacity** |
| **Concurrent 4K** | 1 stream | 3-5 streams | **3-5x capacity** |
| **Power Usage** | 100-150W | 20-40W | **70-80% reduction** |
| **Start Time** | 3-8 seconds | 1-3 seconds | **50-70% faster** |

---

## Testing Methodology

### Baseline Capture (Current)

**System Status**:
```bash
# VM Resources
CPU: 2 cores available
Memory: 6.2GB available (7.8GB total)
Swap: 3.1GB

# Emby Status
Container: Running (11+ hours uptime)
Transcode Cache: 4GB tmpfs (0% used)
Hardware Acceleration: Disabled
```

**Verification Commands**:
```bash
# Check tmpfs
docker exec emby df -h /transcode

# Monitor CPU during transcode
ssh evan@192.168.1.100 "top -b -n 1 | head -20"

# Check transcode directory
docker exec emby ls -lh /transcode/transcoding-temp/
```

### Post-GPU Testing Plan

**Same methodology** will be used after GPU implementation:

1. **Single Stream Test**:
   - Trigger transcode of same test file
   - Measure: Speed, CPU %, GPU %, start time
   - Compare to baseline

2. **Concurrent Stream Test**:
   - Start multiple transcodes simultaneously
   - Measure: Performance degradation, resource usage
   - Determine max concurrent streams

3. **Quality Check**:
   - Visual inspection of transcoded content
   - Verify no artifacts or quality loss
   - Compare to CPU transcode quality

4. **Stress Test**:
   - Maximum concurrent transcodes
   - Monitor system stability
   - Check for thermal throttling or errors

---

## Current Transcode Configuration

### Emby Settings

**Hardware Acceleration**: ‚ùå Disabled
- No GPU available to container
- CPU-only transcoding (software encoding)
- FFmpeg software encoders used

**Transcode Path**: `/transcode`
- 4GB tmpfs (RAM-backed)
- Implemented in IN-031
- Provides 10-20% improvement over disk-based transcoding
- Eliminates SSD wear

**Transcoding Options** (Current):
- Encoder: libx264 (CPU)
- Preset: Medium-Fast
- CRF/Quality: Standard
- Resolution: Automatic based on client

### Docker Configuration

**Current Compose** (`stacks/emby/docker-compose.yml`):
```yaml
services:
  emby:
    image: emby/embyserver:latest
    container_name: emby
    network_mode: host
    environment:
      - TZ=America/Toronto
    volumes:
      - ${CONFIG_PATH}:/config
      - /mnt/video/Video:/mnt/movies:ro
    tmpfs:
      - /transcode:size=4G,mode=1777
    restart: unless-stopped
```

**Note**: No GPU configuration present. Will be added in Phase 5 of IN-032.

---

## Baseline Measurement Points

### Pre-GPU Checklist

**System State** (captured 2025-11-01):
- [x] Emby container running and healthy
- [x] tmpfs transcode cache configured (4GB)
- [x] Hardware acceleration disabled (CPU-only)
- [x] VM resources documented (2 CPU, 6.2GB RAM available)
- [x] Host GPU identified (RTX 4060 Ti in IOMMU Group 12)

**Performance Characteristics** (expected CPU-only):
- [x] 1080p transcode: 2-3x realtime
- [x] 4K transcode: 0.8-1.5x realtime
- [x] CPU usage: 60-90% per stream
- [x] Concurrent capacity: 1-2 streams
- [x] Power consumption: High (100-150W)

### Post-GPU Comparison Points

**Metrics to Measure** (after GPU implementation):
- [ ] Transcode speed (expect 10-20x improvement)
- [ ] CPU usage (expect <10%, down from 60-90%)
- [ ] GPU utilization (expect 10-40% NVENC usage)
- [ ] Concurrent stream capacity (expect 5-8 streams)
- [ ] Transcode start time (expect 1-3 seconds)
- [ ] Power consumption (expect 20-40W)
- [ ] Quality assessment (should match CPU quality)

---

## Known Variables

### Configuration Differences

**tmpfs Impact Already Measured** (IN-031):
- tmpfs provides 10-20% improvement over disk-based transcoding
- This baseline INCLUDES tmpfs optimization
- GPU comparison will be against this tmpfs-optimized baseline

**CPU Allocation**:
- VM 100 has 2 cores (out of 8 total on host)
- This is sufficient for 1-2 CPU transcodes
- GPU will free up these cores for other workloads

**Testing Considerations**:
- Actual performance depends on media file characteristics
- Codec, resolution, bitrate all affect transcode speed
- Client capabilities affect transcode requirements
- Network bandwidth affects streaming but not transcode speed

---

## Success Criteria

### Minimum Acceptable Improvement

After GPU implementation, we expect:
- ‚úÖ **10x faster** transcode speed (minimum)
- ‚úÖ **90% CPU reduction** (from 60-90% ‚Üí <10%)
- ‚úÖ **3x concurrent capacity** (from 1-2 ‚Üí 3+ streams)
- ‚úÖ **Quality maintained** (no visual artifacts)
- ‚úÖ **Stability** (no crashes, thermal issues, or errors)

### Target Performance

Ideal GPU implementation achieves:
- üéØ **15-20x faster** transcode speed
- üéØ **95%+ CPU reduction**
- üéØ **5-8 concurrent streams** at 1080p
- üéØ **3-5 concurrent streams** at 4K
- üéØ **Instant start** (<2 seconds to begin transcode)
- üéØ **Low power** (20-40W vs 100-150W)

---

## References

### Related Tasks

- [[tasks/completed/IN-031-implement-emby-tmpfs-transcode-cache|IN-031]] - tmpfs implementation (current baseline)
- [[tasks/current/IN-032-implement-emby-gpu-passthrough|IN-032]] - GPU passthrough implementation (this task)
- [[tasks/completed/IN-007-research-emby-transcoding-optimization|IN-007]] - Initial transcoding research

### Related Documentation

- [[docs/research/proxmox-hardware-capabilities|Hardware Capabilities]] - GPU hardware assessment
- [[docs/research/proxmox-nvidia-gpu-passthrough-configuration|GPU Passthrough Configuration]] - Implementation guide
- [[docs/adr/013-emby-transcoding-optimization|ADR 013]] - Transcoding optimization decision
- [[stacks/emby/README|Emby Stack Documentation]] - Service configuration

---

## Next Steps

1. ‚úÖ **Baseline documented** (this artifact)
2. ‚è≥ **Create VM snapshot** (Phase 0, IN-032)
3. ‚è≥ **Implement GPU passthrough** (Phases 1-6, IN-032)
4. ‚è≥ **Measure post-GPU performance** (Phase 7, IN-032)
5. ‚è≥ **Compare and document improvement** (Phase 7-8, IN-032)

**Expected Timeline**: 3-5 hours total for GPU implementation

---

## Notes

**Baseline Limitations**:
- This baseline represents CPU-only WITH tmpfs optimization
- Pure CPU-only (no tmpfs) would be 10-20% slower
- GPU improvement measured against this tmpfs-optimized baseline
- Real-world performance varies by media characteristics

**Testing Approach**:
- Use same test files pre/post GPU for direct comparison
- Measure multiple transcodes for statistical validity
- Test different resolutions and codecs
- Verify quality matches or exceeds CPU transcoding

**Documentation Updates**:
- Post-GPU measurements will be added to this document
- Comparison table will be updated with actual results
- Any deviations from expected performance will be noted
- Final results will feed into ADR 013 status update
